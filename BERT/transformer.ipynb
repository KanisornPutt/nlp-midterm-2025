{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:35.208500Z",
     "iopub.status.busy": "2025-03-03T05:54:35.208172Z",
     "iopub.status.idle": "2025-03-03T05:54:35.218403Z",
     "shell.execute_reply": "2025-03-03T05:54:35.217575Z",
     "shell.execute_reply.started": "2025-03-03T05:54:35.208478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:35.219336Z",
     "iopub.status.busy": "2025-03-03T05:54:35.219124Z",
     "iopub.status.idle": "2025-03-03T05:54:39.370614Z",
     "shell.execute_reply": "2025-03-03T05:54:39.369454Z",
     "shell.execute_reply.started": "2025-03-03T05:54:35.219316Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Kanisorn P\\.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:39.371942Z",
     "iopub.status.busy": "2025-03-03T05:54:39.371669Z",
     "iopub.status.idle": "2025-03-03T05:54:39.492376Z",
     "shell.execute_reply": "2025-03-03T05:54:39.491503Z",
     "shell.execute_reply.started": "2025-03-03T05:54:39.371897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !mkdir \"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:39.493511Z",
     "iopub.status.busy": "2025-03-03T05:54:39.493285Z",
     "iopub.status.idle": "2025-03-03T05:54:44.681731Z",
     "shell.execute_reply": "2025-03-03T05:54:44.680822Z",
     "shell.execute_reply.started": "2025-03-03T05:54:39.493479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install pythainlp datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:44.684970Z",
     "iopub.status.busy": "2025-03-03T05:54:44.684723Z",
     "iopub.status.idle": "2025-03-03T05:54:47.643027Z",
     "shell.execute_reply": "2025-03-03T05:54:47.642225Z",
     "shell.execute_reply.started": "2025-03-03T05:54:44.684949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import pythainlp\n",
    "from IPython.display import display\n",
    "from sklearn.utils import resample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.645270Z",
     "iopub.status.busy": "2025-03-03T05:54:47.644807Z",
     "iopub.status.idle": "2025-03-03T05:54:47.649056Z",
     "shell.execute_reply": "2025-03-03T05:54:47.648313Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.645247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_names = [\"clicknext/phayathaibert\", \"pythainlp/phayathai-bert-base\"]\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "MODEL_NAME = \"clicknext/phayathaibert\"\n",
    "RANDOM_STATE = 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.650235Z",
     "iopub.status.busy": "2025-03-03T05:54:47.649915Z",
     "iopub.status.idle": "2025-03-03T05:54:47.707768Z",
     "shell.execute_reply": "2025-03-03T05:54:47.707077Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.650213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '../dataset'\n",
    "df_train = pd.read_csv(dataset_path + \"/train.csv\")\n",
    "df_test = pd.read_csv(dataset_path + \"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.708822Z",
     "iopub.status.busy": "2025-03-03T05:54:47.708535Z",
     "iopub.status.idle": "2025-03-03T05:54:47.715004Z",
     "shell.execute_reply": "2025-03-03T05:54:47.713998Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.708796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (362, 5)\n",
      "Test data shape:  (90, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", df_train.shape)\n",
    "print(\"Test data shape: \", df_test.shape)\n",
    "record_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.716139Z",
     "iopub.status.busy": "2025-03-03T05:54:47.715810Z",
     "iopub.status.idle": "2025-03-03T05:54:47.741808Z",
     "shell.execute_reply": "2025-03-03T05:54:47.741029Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.716108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>set</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>granularity ควรจะมีค่าต่ำ เพราะว่าเราต้องการทร...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>เห็นด้วย เพราะเป็นการเก็บข้อมูลจากหลาย  users ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>granularity ควรเป็น #checkout events/ #cookies...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>เห็นด้วย ให้ X~Binomial(N,p) โดย p เป็นอัตราส่...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>เห็นด้วย เนื่องจากการทดสอบ A/B Testing เป็นวิธ...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID set                                           question  \\\n",
       "0   0  Q2  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "1   1  Q3  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "2   2  Q2  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "3   3  Q3  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "4   4  Q1  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "\n",
       "                                              answer  score  \n",
       "0  granularity ควรจะมีค่าต่ำ เพราะว่าเราต้องการทร...    0.0  \n",
       "1  เห็นด้วย เพราะเป็นการเก็บข้อมูลจากหลาย  users ...    5.0  \n",
       "2  granularity ควรเป็น #checkout events/ #cookies...    5.0  \n",
       "3  เห็นด้วย ให้ X~Binomial(N,p) โดย p เป็นอัตราส่...    2.0  \n",
       "4  เห็นด้วย เนื่องจากการทดสอบ A/B Testing เป็นวิธ...    4.5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.742974Z",
     "iopub.status.busy": "2025-03-03T05:54:47.742616Z",
     "iopub.status.idle": "2025-03-03T05:54:47.764358Z",
     "shell.execute_reply": "2025-03-03T05:54:47.763524Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.742943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>362</td>\n",
       "      <td>362</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Q4</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>ใช้ เพราะเป็นการใช้ scientific method มาช่วยหา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        set                                           question  \\\n",
       "count   362                                                362   \n",
       "unique    4                                                  4   \n",
       "top      Q4  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "freq     91                                                 91   \n",
       "\n",
       "                                                   answer  \n",
       "count                                                 362  \n",
       "unique                                                362  \n",
       "top     ใช้ เพราะเป็นการใช้ scientific method มาช่วยหา...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['set', 'question', 'answer']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.765513Z",
     "iopub.status.busy": "2025-03-03T05:54:47.765239Z",
     "iopub.status.idle": "2025-03-03T05:54:47.786310Z",
     "shell.execute_reply": "2025-03-03T05:54:47.785458Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.765489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>362.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.021409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.990644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "count  362.000000\n",
       "mean     3.021409\n",
       "std      1.990644\n",
       "min      0.000000\n",
       "25%      1.000000\n",
       "50%      3.500000\n",
       "75%      5.000000\n",
       "max      5.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['score']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.787438Z",
     "iopub.status.busy": "2025-03-03T05:54:47.787175Z",
     "iopub.status.idle": "2025-03-03T05:54:47.800576Z",
     "shell.execute_reply": "2025-03-03T05:54:47.799716Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.787412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>set</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>ได้ เพราะ โจทย์นี้ ตัวแปรคือค่าเฉลี่ยของอัตราก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>Q4</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>50/50 มีข้อดีก็คือสามารถเก็บผลการทดสอบได้ไวกว่...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>364</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>1.จำนวนการเข้าชม 2. จำนวนการคลิกโฆษณา 3.เวลาที...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>เห็นด้วย เพราะการคลิกมีผลลัพธ์ได้ 2 รูปแบบ นั่...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366</td>\n",
       "      <td>Q4</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>50/50 - จะใช้เวลาเก็บข้อมูลน้อยกว่า แต่มีความเ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID set                                           question  \\\n",
       "0  362  Q3  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "1  363  Q4  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "2  364  Q2  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "3  365  Q3  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "4  366  Q4  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "\n",
       "                                              answer  \n",
       "0  ได้ เพราะ โจทย์นี้ ตัวแปรคือค่าเฉลี่ยของอัตราก...  \n",
       "1  50/50 มีข้อดีก็คือสามารถเก็บผลการทดสอบได้ไวกว่...  \n",
       "2  1.จำนวนการเข้าชม 2. จำนวนการคลิกโฆษณา 3.เวลาที...  \n",
       "3  เห็นด้วย เพราะการคลิกมีผลลัพธ์ได้ 2 รูปแบบ นั่...  \n",
       "4  50/50 - จะใช้เวลาเก็บข้อมูลน้อยกว่า แต่มีความเ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.801744Z",
     "iopub.status.busy": "2025-03-03T05:54:47.801480Z",
     "iopub.status.idle": "2025-03-03T05:54:47.821475Z",
     "shell.execute_reply": "2025-03-03T05:54:47.820450Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.801724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...</td>\n",
       "      <td>ได้ เพราะ โจทย์นี้ ตัวแปรคือค่าเฉลี่ยของอัตราก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       set                                           question  \\\n",
       "count   90                                                 90   \n",
       "unique   4                                                  4   \n",
       "top     Q3  Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาต...   \n",
       "freq    23                                                 23   \n",
       "\n",
       "                                                   answer  \n",
       "count                                                  90  \n",
       "unique                                                 90  \n",
       "top     ได้ เพราะ โจทย์นี้ ตัวแปรคือค่าเฉลี่ยของอัตราก...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['set', 'question', 'answer']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.822493Z",
     "iopub.status.busy": "2025-03-03T05:54:47.822268Z",
     "iopub.status.idle": "2025-03-03T05:54:47.834857Z",
     "shell.execute_reply": "2025-03-03T05:54:47.834014Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.822474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาตให้ผู้ใช้อัปโหลด แชร์ และดูวิดีโอได้ แฮมทาโร่ เป็นหัวหน้าทีมการตลาดของ Hamtube และเขาต้องการทราบว่าการย้ายตำแหน่งของโฆษณาจะช่วยเพิ่มยอดขาย (ผู้ใช้คลิกโฆษณามากขึ้น) หรือไม่ ดังนั้นเขาตัดสินใจที่จะดำเนินการทดลอง A/B testing. \n"
     ]
    }
   ],
   "source": [
    "q = 'Hamtube เป็นแพลตฟอร์มดูวีดีโอออนไลน์ ที่อนุญาตให้ผู้ใช้อัปโหลด แชร์ และดูวิดีโอได้ แฮมทาโร่ เป็นหัวหน้าทีมการตลาดของ Hamtube และเขาต้องการทราบว่าการย้ายตำแหน่งของโฆษณาจะช่วยเพิ่มยอดขาย (ผู้ใช้คลิกโฆษณามากขึ้น) หรือไม่ ดังนั้นเขาตัดสินใจที่จะดำเนินการทดลอง A/B testing. '\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.836192Z",
     "iopub.status.busy": "2025-03-03T05:54:47.835887Z",
     "iopub.status.idle": "2025-03-03T05:54:47.859556Z",
     "shell.execute_reply": "2025-03-03T05:54:47.858790Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.836164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1. granularity ควรเป็นอะไร และความยาวของ attribution period ควรเป็นเท่าไหร่ จงอธิบายเหตุผล\n",
      "\n",
      "Q2. แฮมทาโร่เลือกที่จะใช้ binomial distribution เพื่อแทน distribution ของการทำ A/B testing ในครั้งนี้ คุณเห็นด้วยหรือไม่เห็นด้วยกับแฮมทาโร่ เพราะเหตุใด\n",
      "\n",
      "Q3. อธิบายเหตุผลที่แฮมทาโร่ควรใช้ A/B testing ในการทดสอบ หรือเสนอข้อโต้แย้งหากคุณไม่เห็นด้วย พร้อมกับอธิบายเหตุผล\n",
      "\n",
      "Q4. แฮมทาโร่จะต้องเลือกว่าอยากให้สัดส่วนของ user ที่เห็นโฆษณาตำแหน่งเก่า ต่อ user ที่เห็นโฆษณาตำแหน่งใหม่เป็นเท่าไร โดยตอนนี้แฮมทาโร่กำลังลังเลระหว่างสัดส่วน 50/50 กับ สัดส่วน 80/20 จงอธิบายข้อดีข้อเสียของการเลือกสัดส่วนแต่ละแบบ และตอบว่าแบบใดที่น่าจะเหมาะสมกับปัญหานี้มากกว่า\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set\n",
       "Q1     91\n",
       "Q4     91\n",
       "Q2     90\n",
       "Q3     90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f\"Q{i+1}. {df_train['question'].unique()[i][269:]}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "df_train[['set']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.860674Z",
     "iopub.status.busy": "2025-03-03T05:54:47.860482Z",
     "iopub.status.idle": "2025-03-03T05:54:47.868740Z",
     "shell.execute_reply": "2025-03-03T05:54:47.867874Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.860657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "Q2     23\n",
       "Q3     23\n",
       "Q1     22\n",
       "Q4     22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['set']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "5.00     150\n",
       "1.00      58\n",
       "0.00      50\n",
       "3.00      26\n",
       "2.00      20\n",
       "4.00      15\n",
       "0.50      10\n",
       "4.50       9\n",
       "3.50       8\n",
       "1.50       8\n",
       "2.50       5\n",
       "0.75       1\n",
       "4.25       1\n",
       "4.75       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['score']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Q2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score\n",
       "5.00     19\n",
       "4.75      1\n",
       "4.50      2\n",
       "4.25      1\n",
       "4.00      5\n",
       "3.50      8\n",
       "3.00      3\n",
       "2.50      4\n",
       "2.00      1\n",
       "1.50      1\n",
       "0.75      1\n",
       "0.50      1\n",
       "0.00     43\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Q3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score\n",
       "5.0      66\n",
       "3.0       1\n",
       "2.0      10\n",
       "1.0       9\n",
       "0.0       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Q1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score\n",
       "5.0       9\n",
       "4.5       5\n",
       "4.0       3\n",
       "3.0      10\n",
       "2.5       1\n",
       "2.0       8\n",
       "1.5       7\n",
       "1.0      39\n",
       "0.5       7\n",
       "0.0       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Q4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score\n",
       "5.0      56\n",
       "4.5       2\n",
       "4.0       7\n",
       "3.0      12\n",
       "2.0       1\n",
       "1.0      10\n",
       "0.5       2\n",
       "0.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in df_train[\"set\"].unique():\n",
    "\n",
    "    # Filter data for the current question\n",
    "    df_q = df_train[df_train[\"set\"] == q]\n",
    "    print(f\"Question: {q}\")\n",
    "    display(df_q[['score']].value_counts().sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.869910Z",
     "iopub.status.busy": "2025-03-03T05:54:47.869624Z",
     "iopub.status.idle": "2025-03-03T05:54:47.885749Z",
     "shell.execute_reply": "2025-03-03T05:54:47.884988Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.869882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "แฮมทาโร่เลือกที่จะใช้ binomial distribution เพื่อแทน distribution ของการทำ A/B testing ในครั้งนี้ คุณเห็นด้วยหรือไม่เห็นด้วยกับแฮมทาโร่ เพราะเหตุใด\n",
      "\n",
      "0.0\n",
      "User Level: การตั้งค่า granularity ที่ระดับผู้ใช้ (user level) สามารถให้ข้อมูลที่ละเอียดมากเกี่ยวกับพฤติกรรมของแต่ละบุคคล ทำให้ง่ายต่อการทำให้กลยุทธ์ตลาดเป็นไปตามความต้องการของกลุ่มเป้าหมาย\n",
      "\n",
      "Channel Level: การรวบรวมข้อมูลที่ระดับช่องทาง (channel level) อาจช่วยให้ทราบถึงประสิทธิภาพของแต่ละช่องทางตลาด ทำให้สามารถปรับกลยุทธ์การตลาดในแต่ละช่องทางได้\n",
      "\n",
      "Campaign Level: การตั้งค่า granularity ที่ระดับแคมเปญ (campaign level) จะให้ภาพรวมของประสิทธิภาพของแคมเปญต่าง ๆ และช่วยในการวิเคราะห์ผลลัพธ์ของกิจกรรมตลาดทั้งหมด\n",
      "Attribution period ควรเป็นเท่าไหร่ขึ้นอยู่กับลักษณะธุรกิจและลักษณะการพฤติกรรมของลูกค้า. ถ้าธุรกิจมีลูกค้าที่ต้องการเวลาในการตัดสินใจนาน, attribution period ควรเป็นระยะยาวเพื่อครอบคลุมกระบวนการนี้. ส่วนถ้าลูกค้ามีรูปแบบการพฤติกรรมที่รวดเร็ว, attribution period สั้นก็อาจเพียงพอในการวิเคราะห์และปรับกลยุทธ์ตลาด. การกำหนดระยะเวลานี้ควรสอดคล้องกับวัตถุประสงค์ของการตลาดและการทำธุรกิจ.\n",
      "\n",
      "3.5\n",
      "granularity = #ads_clicked/#ads_seen\n",
      "#ads_clicked คือ จำนวนคนที่เห็น ads แล้วคลิก (ไม่นับซ้ำคนเดิม)\n",
      "#ads_seen คือ จำนวนคนที่เห็น ads (ไม่นับซ้ำคนเดิม)\n",
      "เพราะ เราต้องการวัดยอดขายจากจำนวนที่ผู้ใช้คลิกโฆษณา\n",
      "attribution period = 1 day\n",
      "เพราะการคลิกโฆษณาเกิดขึ้นในระยะเวลาสั้นๆ การวัดภายในหนึ่งวันจึงเหมาะสม\n",
      "\n",
      "4.0\n",
      "จำนวนคลิกโฆษณาทั้งหมด จำนวนผู้เข้าชมทั้งหมด เพราะเป็นตัวบอกว่าผู้ชมสนใจโฆษณามากน้อยแค่ไหน ส่วน attribution period ควรเป็น 1 สัปดาห์ เพราะ แต่ละวันอาจจะมีผลต่อการรับชม เช่น วันเสาร์/วันอาทิตย์ ที่เป็นวันหยุดอาจจะทำให้มีผลต่อยอดการคลิก จึงควรคิดเป็น 1 สัปดาห์\n",
      "\n",
      "0.0\n",
      "Granularity อาจจะเป็น User-level หรือ Session-level โดยแล้วแต่งบประมาณและความเร็วที่ต้องการ\n",
      "\n",
      "- User-level ละเอียดกว่า สามารถตามผลในระยะยาวได้ สามารถทำ user segmentation โดยแบ่งตาม characteristics เช่น ความถี่ในการเข้าเว็บไซต์, ความชอบส่วนบุคคล, ข้อมูลส่วนตัว (ดังเช่นใน facebook targeted ads จะเขียนว่า Why am I seeing this ads? ถ้ากดเข้าไปดูจะพบว่ามีหลายปัจจัย เช่น คุณกดไลค์เพจนั้น คุณอายุเท่านี้ คุณเป็นเพศนี้)\n",
      "- Session-level แม้ไม่สามารถ track หรือทำ persona ได้ แต่มีความเร็วที่มากกว่าและข้อมูลสามารถนำมา analyze ได้ง่ายกว่า\n",
      "\n",
      "สำหรับ Attribution Period เลือกเป็นระดับสัปดาห์ เนื่องจากถ้าสั้นเกินไปอาจไม่เห็นผล และยาวกว่านี้การตัดสินใจดู ads อาจเกิดจากปัจจัยอื่น\n",
      "\n",
      "0.0\n",
      "Granularity: Granularity ควรเลือกให้สอดคล้องกับวิธีที่ผู้ใช้มีปฏิสัมพันธ์กับโฆษณา หากโฆษณามีการมีส่วนร่วมสูง (เช่น การคลิก) สิ่งนี้ช่วยให้แฮมทาโร่เข้าใจพฤติกรรมของผู้ใช้ในช่วงเวลาสั้นๆ ได้ดีขึ้น\n",
      "Attribution Period: ระยะเวลานี้ควรเพียงพอที่จะครอบคลุมปฏิสัมพันธ์ปกติของผู้ใช้กับโฆษณาและการตัดสินใจซื้อ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 2\n",
    "sample = df_train[df_train['set'] == f'Q{q}'].sample(5)\n",
    "\n",
    "print(df_train['question'].unique()[q-1][269:])\n",
    "print()\n",
    "    \n",
    "for record in sample.iterrows():\n",
    "    print(record[1]['score'])\n",
    "    print(record[1]['answer'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.886913Z",
     "iopub.status.busy": "2025-03-03T05:54:47.886694Z",
     "iopub.status.idle": "2025-03-03T05:54:47.891003Z",
     "shell.execute_reply": "2025-03-03T05:54:47.890001Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.886894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['เพื่อที่', 'วันนี้', 'รึ', 'ช้าๆ', 'บ่อย', 'ก็ได้', 'บางขณะ', 'จนแม้น', 'พอเพียง', 'มันๆ', 'ข้า', 'แก', 'แค่ว่า', 'บางคราว', 'คล้ายกันกับ', 'ที', 'ตลอดไป', 'ทั้งปวง', 'เมื่อคราว', 'กัน', 'กลุ่ม', 'อย่างใด', 'ที่', 'แต่ก่อน', 'เนี่ยเอง', 'ควร', 'ฝ่ายใด', 'สิ้นกาลนาน', 'ให้ดี', 'จนทั่ว', 'ไม่ใช่', 'เพื่อ', 'เรียก', 'หมด', 'เท่านี้', 'ค่อนข้าง', 'ตลอด', 'ทีๆ', 'นอกนั้น', 'ด้วยเพราะ', 'เช่นดัง', 'หมดกัน', 'บอกแล้ว', 'ช่วงนั้น', 'คล้ายกับ', 'ระหว่าง', 'ถ้าหาก', 'ได้แก่', 'เสร็จสมบูรณ์', 'บ้าง', 'จาก', 'สําหรับ', 'ใกล้ๆ', 'หลังจาก', 'คุณๆ', 'เป็นต้นมา', 'ครั้งหลังสุด', 'พร้อมกัน', 'จึงจะ', 'ฝ่าย', 'อดีต', 'จริง', 'ทั้ง', 'อย่างยิ่ง', 'แสดงว่า', 'เชื่อว่า', 'นับแต่นั้น', 'ร่วมกัน', 'รวมถึง', 'ๆ', 'ขอ', 'แก้ไข', 'ที่นั้น', 'ครั้งหนึ่ง', 'คราวที่', 'พอกัน', 'คราวหน้า', 'ก็แล้วแต่', 'ก็ตาม', 'ค่อนมาทาง', 'จัดหา', 'สั้นๆ', 'เช่นเดียวกับ', 'จ๊ะ', 'พอแล้ว', 'เชื่อมั่น', 'เชื่อ', 'จากนี้ไป', 'คล้ายกับว่า', 'ข้าพเจ้า', 'สุด', 'ด้วยกัน', 'พอสม', 'แต่อย่างใด', 'ใหม่', 'เรื่อยๆ', 'พร้อม', 'เช่นที่เคย', 'คราวก่อน', 'ช่วงนี้', 'หนึ่ง', 'เปลี่ยน', 'จ้ะ', 'ภายใน', 'เป็น', 'จัดตั้ง', 'หารือ', 'เป็นที่', 'ใหญ่ๆ', 'พวกนี้', 'พอเหมาะ', 'ละ', 'ทำไม', 'ตามแต่', 'ถือว่า', 'ต่าง', 'ที่แล้ว', 'มิใช่', 'ค่อยๆ', 'ขวาง', 'ยาวนาน', 'แต่เมื่อ', 'ขวางๆ', 'มักจะ', 'เปิดเผย', 'พวกมึง', 'นอกจากที่', 'พวก', 'หาใช่', 'แม้แต่', 'คราที่', 'ครบ', 'สมัย', 'ดังเคย', 'ก่อน', 'บอก', 'บัดนี้', 'หรือไง', 'ที่แท้จริง', 'ที่ได้', 'ทุกคราว', 'ทําให้', 'ง่ายๆ', 'ฉะนั้น', 'ซะจนถึง', 'เพื่อให้', 'เกี่ยวกับ', 'พวกที่', 'เหล่านั้น', 'นาน', 'ตลอดกาลนาน', 'เอง', 'พร้อมเพียง', 'ซะ', 'เหตุนั้น', 'เสียด้วย', 'นั่นเอง', 'คราวนี้', 'ยืนยัน', 'พวกเขา', 'จัง', 'ช่วงก่อน', 'ช่วงต่อไป', 'กู', 'น้อย', 'ให้', 'เป็นการ', 'วันใด', 'ยิ่งแล้ว', 'พอสมควร', 'ประสบ', 'ครั้งหลัง', 'ใหม่ๆ', 'เกี่ยวเนื่อง', 'ยืนยาว', 'ของ', 'เต็มๆ', 'นี้เอง', 'เป็นที', 'เรา', 'คราวโน้น', 'ครั้งนั้น', 'พร้อมที่', 'ทุกที่', 'ข้างเคียง', 'เหล่า', 'แต่ไหน', 'ก็ตามแต่', 'มั้ยนะ', 'ด้วยเหตุที่', 'ทั้งเป็น', 'ตลอดระยะเวลา', 'วันนั้น', 'กันดีกว่า', 'ล้วนจน', 'ถึงแม้จะ', 'ทั้งนี้', 'เสร็จสิ้น', 'พอดี', 'ช่วงๆ', 'ช้านาน', 'เป็นอันว่า', 'ไกล', 'ได้รับ', 'รวม', 'ถูกๆ', 'เข้า', 'นี่ไง', 'ก็คือ', 'ถึงแม้ว่า', 'ถึงแก่', 'ครั้ง', 'อื่นๆ', 'ใช่', 'แม้', 'เหตุ', 'กระทำ', 'คะ', 'คล้ายว่า', 'เริ่ม', 'แต่ถ้า', 'ได้ที่', 'ยิ่ง', 'นู่น', 'จนบัดนี้', 'ซึ่งก็คือ', 'นั้นไว', 'นำ', 'อย่างไร', 'เผื่อจะ', 'ส่วนนั้น', 'จริงๆ', 'ช่วย', 'ทุกที', 'ความ', 'มิฉะนั้น', 'ทีเถอะ', 'ครบครัน', 'จนกว่า', 'หาก', 'บัดนั้น', 'หลัง', 'การ', 'เล็กๆ', 'ไกลๆ', 'ขาด', 'จัดการ', 'ร่วม', 'แม้ว่า', 'ทั้งๆ', 'เท่าไร', 'ทั้งตัว', 'มี', 'ทำไร', 'บ่อยครั้ง', 'ทุกวัน', 'ไม่เป็นไร', 'ด้วยว่า', 'เมื่อคราวที่', 'ส่วนใด', 'ฯล', 'แม้นว่า', 'โต', 'นี่แน่ะ', 'ซะจน', 'ณ', 'สูงๆ', 'จรด', 'ใน', 'จวนจะ', 'พื้นๆ', 'นอกจากว่า', 'อาจเป็น', 'ส่วน', 'เช่นดังเก่า', 'เสมือนว่า', 'นี้', 'ทันที', 'ชาว', 'ยังไง', 'รึว่า', 'ค่ะ', 'ที่ว่า', 'บางที่', 'อย่างนี้', 'เร็ว', 'กันไหม', 'นะ', 'เป็นอันๆ', 'ส่วนมาก', 'จ๋า', 'กำลังจะ', 'ยกให้', 'อย่างหนึ่ง', 'จริงๆจังๆ', 'สิ่งใด', 'ภาย', 'ทุกคน', 'มิ', 'นอกจากนั้น', 'สิ่งไหน', 'ภายหน้า', 'คง', 'จรดกับ', 'ปรับ', 'ขณะเดียวกัน', 'ทันทีทันใด', 'เสียแล้ว', 'เป็นต้น', 'นี่แหละ', 'ที่แท้', 'อาจจะ', 'หากว่า', 'คราวๆ', 'คิดว่า', 'สูงส่ง', 'อะไร', 'รับรอง', 'พวกโน้น', 'แห่งใด', 'ให้ไป', 'จากนั้น', 'มัน', 'อันที่', 'พอตัว', 'ดั่งกับ', 'เพียงใด', 'ตั้งแต่', 'ตนเอง', 'จวบจน', 'เท่า', 'เพียงไหน', 'ด้วยเหตุว่า', 'อันละ', 'เป็นด้วย', 'ยอม', 'เฉย', 'นักๆ', 'เกือบจะ', 'ครั้งก่อน', 'ในระหว่าง', 'น้อยกว่า', 'เห็นแก่', 'ล้วน', 'ทำให้', 'ที่ไหน', 'ทั้งสิ้น', 'ถึงบัดนั้น', 'เยอะแยะ', 'แห่ง', 'เสียนั่นเอง', 'อย่างไหน', 'ว่า', 'เช่นนั้นเอง', 'ล้วนแต่', 'ด้าน', 'พวกท่าน', 'จำพวก', 'ทุก', 'ไว้', 'พวกนั้น', 'เห็นว่า', 'เช่นเดียวกัน', 'ต้อง', 'ส่วนด้อย', 'รวด', 'เพิ่งจะ', 'พร้อมทั้ง', 'นับจากนี้', 'เห็น', 'หลาย', 'คำ', 'ยังงั้น', 'แก่', 'มั้ยนั่น', 'อัน', 'เหลือเกิน', 'อาจเป็นด้วย', 'ใช่ไหม', 'อันที่จะ', 'มองว่า', 'เมื่อเช้า', 'ตลอดวัน', 'ย่อม', 'ฉัน', 'ดั่ง', 'ที่ละ', 'ครบถ้วน', 'ในช่วง', 'เล็กน้อย', 'ผิดๆ', 'คราหนึ่ง', 'บางๆ', 'ซะก่อน', 'พอ', 'ถึงเมื่อไร', 'เมื่อครั้ง', 'เกือบๆ', 'หน่อย', 'ภาคฯ', 'ยืนยง', 'ตลอดจน', 'มีแต่', 'กระทั่ง', 'อนึ่ง', 'กระนั้น', 'เมื่อคราวก่อน', 'ต่างๆ', 'แต่ละ', 'ช่วงหลัง', 'แหละ', 'นี่นา', 'เขียน', 'ช่วงถัดไป', 'ส่วนเกิน', 'ด้วยที่', 'เพียงแค่', 'เสียจนถึง', 'ยาว', 'เป็นดัง', 'รวดเร็ว', 'หากแม้น', 'เพียง', 'เท่ากับ', 'ไป', 'ทั่ว', 'สมัยนี้', 'ทว่า', 'ภาค', 'พึง', 'ในที่', 'ได้แต่', 'เฉกเช่น', 'แต่นั้น', 'ให้แก่', 'และ', 'ตนฯ', 'แค่เพียง', 'คราวหนึ่ง', 'รับ', 'เป็นเพียงว่า', 'กำหนด', 'น้อยๆ', 'ส่วนที่', 'ทั้งนั้น', 'ส่วนน้อย', 'เสียนั่น', 'เผื่อที่', 'มากมาย', 'แต่ก็', 'เป็นแต่เพียง', 'นี่เอง', 'ประการหนึ่ง', 'ครา', 'เพิ่ม', 'กว้างๆ', 'ครั้งกระนั้น', 'แล้ว', 'มาก', 'เกิน', 'ก่อนๆ', 'แค่', 'จากนี้', 'ด้วยเหตุเพราะ', 'จัดแจง', 'จนเมื่อ', 'แต่ไร', 'ถ้าจะ', 'กลุ่มๆ', 'ทรง', 'จะ', 'จนแม้', 'ขณะใด', 'ราย', 'ทุกหน', 'เช่นนั้น', 'ไป่', 'เช่นที่', 'ซึ่ง', 'กำลัง', 'บางที', 'ด้วยเหตุนี้', 'คล้าย', 'บางครา', 'เสีย', 'เหตุไร', 'ช่วงแรก', 'นับตั้งแต่', 'ออก', 'ตั้ง', 'ทุกอย่าง', 'ขณะ', 'อย่างมาก', 'จึงเป็น', 'จวน', 'คราวนั้น', 'หรือไม่', 'พร้อมกับ', 'เชื่อถือ', 'แล้วเสร็จ', 'บางครั้ง', 'แห่งโน้น', 'นับแต่', 'ใครๆ', 'เมื่อไหร่', 'กล่าวคือ', 'ไม่', 'ยิ่งจน', 'กระผม', 'แค่จะ', 'หรือ', 'ช่วงหน้า', 'ซึ่งกันและกัน', 'ตามๆ', 'พยายาม', 'เมื่อก่อน', 'จัด', 'ยืนนาน', 'จนถึง', 'ทั้งที', 'ใต้', 'เผื่อว่า', 'ยัง', 'แห่งไหน', 'เลย', 'ใกล้', 'เพิ่ง', 'ก็ตามที', 'ต่างหาก', 'ยิ่งนัก', 'สูงกว่า', 'ย่อย', 'ล่าสุด', 'เท่ากัน', 'นางสาว', 'เพิ่มเติม', 'เรียบ', 'นั่น', 'ถึงเมื่อใด', 'ทุกๆ', 'มั้ย', 'เผื่อ', 'ใหญ่โต', 'เสียนี่กระไร', 'ไม่ว่า', 'นานๆ', 'เช่นเคย', 'อย่าง', 'ยิ่งขึ้นไป', 'คงจะ', 'บัดเดี๋ยวนี้', 'ใดๆ', 'เพียงไร', 'เหตุนี้', 'คุณ', 'เสร็จแล้ว', 'นิด', 'สิ่ง', 'อันไหน', 'ผ่าน', 'เอา', 'เข้าใจ', 'จึง', 'เกือบ', 'อย่างไรเสีย', 'ประมาณ', 'น่าจะ', 'วันไหน', 'กว่า', 'อันจะ', 'ตลอดกาล', 'เกี่ยวๆ', 'ด้วยเหตุนั้น', 'เนี่ย', 'ทั้งที่', 'ขณะนี้', 'เยอะๆ', 'ยิ่งจะ', 'บางกว่า', 'มึง', 'ต่อ', 'ผู้', 'ไร', 'หนอย', 'พวกแก', 'อย่างไรก็ได้', 'เช่น', 'เกินๆ', 'มุ่งหมาย', 'ประกอบ', 'ภายภาค', 'ส่ง', 'คราวละ', 'หมดสิ้น', 'แยะ', 'ค่อน', 'ยังงี้', 'คราวไหน', 'บ่อยกว่า', 'ภายหลัง', 'สืบเนื่อง', 'ข้างๆ', 'เสร็จ', 'ช่วง', 'แต่ต้อง', 'พอควร', 'ตน', 'ตาม', 'เดียว', 'แต่ว่า', 'ปัจจุบัน', 'เกี่ยวข้อง', 'ทุกทาง', 'ประการฉะนี้', 'นิดๆ', 'จนตลอด', 'นี่', 'ส่วนดี', 'กันและกัน', 'น่ะ', 'ค่อนข้างจะ', 'เราๆ', 'ซึ่งๆ', 'เน้น', 'ครานี้', 'จนกระทั่ง', 'จง', 'คล้ายกัน', 'ทัน', '\\ufeffๆ', 'สมัยโน้น', 'จัดทำ', 'แยะๆ', 'อย่างละ', 'ยังจะ', 'พวกฉัน', 'ทุกชิ้น', 'เพียงพอ', 'ต่อกัน', 'ด้วยประการฉะนี้', 'ทุกตัว', 'พึ่ง', 'เสียนี่', 'เป็นเพียง', 'บอกว่า', 'บ่อยๆ', 'มั๊ย', 'นั่นแหละ', 'อันๆ', 'เนื่องจาก', 'ซึ่งก็', 'เช่นกัน', 'สุดๆ', 'นั่นไง', 'หนอ', 'แต่ทว่า', 'บางแห่ง', 'เมื่อเย็น', 'เพราะฉะนั้น', 'เถอะ', 'เป็นๆ', 'มากกว่า', 'อย่างเดียว', 'อื่น', 'กันเถอะ', 'สมัยก่อน', 'สิ่งนั้น', 'เป็นที่สุด', 'เกิด', 'ใคร่จะ', 'ง่าย', 'เยอะ', 'แต่เพียง', 'เร็วๆ', 'เป็นอันมาก', 'ไม่ค่อยจะ', 'หากแม้นว่า', 'คราวใด', 'ถึงบัดนี้', 'เท่าใด', 'ข้างต้น', 'ขั้น', 'อาจ', 'จะได้', 'เสียยิ่งนัก', 'จด', 'เพราะ', 'ยิ่งใหญ่', 'มิได้', 'ครับ', 'เช่นก่อน', 'เสมือนกับ', 'ให้แด่', 'ถึงแม้', 'สูงสุด', 'ตลอดมา', 'พูด', 'สบาย', 'เป็นอัน', 'ทันใดนั้น', 'ตรงๆ', 'จวนเจียน', 'เช่นไร', 'ตลอดทั่วถึง', 'เมื่อวาน', 'ตามด้วย', 'เสียจนกระทั่ง', 'ไหนๆ', 'ทุกอัน', 'แล้วกัน', 'ค่อย', 'กันนะ', 'มา', 'ก็', 'ตลอดถึง', 'นับ', 'มุ่งเน้น', 'กับ', 'ถูก', 'ฉะนี้', 'จังๆ', 'ที่สุด', 'ยังโง้น', 'เห็นควร', 'ไม่ค่อย', 'ทีไร', 'อย่างนั้น', 'เหลือ', 'คราใด', 'พอที่', 'เห็นจะ', 'เต็มไปหมด', 'พวกคุณ', 'สามารถ', 'จนขณะนี้', 'ครั้งไหน', 'พวกกู', 'หาความ', 'ผู้ใด', 'ประการใด', 'ขณะนั้น', 'รวมด้วย', 'ฯ', 'ซึ่งได้แก่', 'ข้าง', 'ทำๆ', 'ไฉน', 'จัดงาน', 'รวมทั้ง', 'แต่เดิม', 'ยังแต่', 'ทีละ', 'เสร็จกัน', 'เช่นใด', 'เหตุผล', 'นับแต่ที่', 'ดังกับว่า', 'เอ็ง', 'ปิด', 'ใหญ่', 'กันดีไหม', 'นอกเหนือจาก', 'หรือเปล่า', 'นี้แหล่', 'ดั่งเก่า', 'เมื่อครั้งก่อน', 'ที่ซึ่ง', 'อันใด', 'เป็นเพื่อ', 'สิ้น', 'อันได้แก่', 'เป็นเพราะ', 'ขณะหนึ่ง', 'นอก', 'ดังกล่าว', 'ทุกสิ่ง', 'อีก', 'นั้นๆ', 'สิ่งนี้', 'เพียงแต่', 'เปิด', 'ที่แห่งนั้น', 'ตลอดทั่วทั้ง', 'ด้วยเช่นกัน', 'ข้างบน', 'พบ', 'ก็ต่อเมื่อ', 'เมื่อนั้น', 'เมื่อ', 'เพียงเพราะ', 'ครั้งละ', 'เช่นเมื่อ', 'มัก', 'เล็ก', 'เสียจน', 'โดย', 'กันเอง', 'นิดหน่อย', 'เสียก่อน', 'อย่างโน้น', 'ทุกครั้ง', 'ช่วงระหว่าง', 'เท่านั้น', 'ถึงเมื่อ', 'ครั้งครา', 'เดียวกัน', 'เคย', 'ยิ่งเมื่อ', 'ทั้งหลาย', 'ได้มา', 'พอจะ', 'ตลอดศก', 'อย่างๆ', 'ครั้งๆ', 'ทุกครา', 'ทั้งนั้นด้วย', 'ร่วมด้วย', 'ครั้งที่', 'เปลี่ยนแปลง', 'คงอยู่', 'นาง', 'ระยะ', 'จ้า', 'ดังเก่า', 'ทุกวันนี้', 'พอที', 'ครานั้น', 'เป็นต้นไป', 'ภายภาคหน้า', 'แต่จะ', 'เท่าที่', 'นับแต่นี้', 'ที่ๆ', 'ระยะๆ', 'พา', 'พวกกัน', 'ภายนอก', 'ทั้งหมด', 'เมื่อวันวาน', 'ปรากฏ', 'ตลอดเวลา', 'คือ', 'สำคัญ', 'เป็นเพราะว่า', 'แสดง', 'จำ', 'ใช้', 'ก่อนหน้า', 'เพื่อที่จะ', 'ครั้งใด', 'พวกนู้น', 'นำมา', 'สั้น', 'คราวหลัง', 'เก็บ', 'คิด', 'แล้วแต่', 'ไง', 'ทุกเมื่อ', 'อย่างน้อย', 'อย่างที่', 'ให้มา', 'เมื่อใด', 'เถิด', 'เพราะว่า', 'ช่วงที่', 'เกี่ยวกัน', 'เพื่อว่า', 'ทาง', 'จัดให้', 'เต็มไปด้วย', 'น่า', 'อยู่', 'ยิ่งกว่า', 'แต่ที่', 'มุ่ง', 'จริงจัง', 'บาง', 'ก็ดี', 'จู่ๆ', 'ขณะใดๆ', 'ดัง', 'รือว่า', 'หรือไร', 'เรื่อย', 'แห่งนี้', 'ถึงอย่างไร', 'เมื่อคืน', 'ไหน', 'รือ', 'ข้าฯ', 'แค่ไหน', 'ซึ่งกัน', 'ยิ่งขึ้น', 'อย่างเช่น', 'ที่จริง', 'แค่นั้น', 'ลง', 'มอง', 'หน', 'พบว่า', 'สมัยนั้น', 'เมื่อนี้', 'นอกจากนี้', 'ถ้า', 'นับจากนั้น', 'แค่นี้', 'เพียงเพื่อ', 'ถึง', 'ปรากฏว่า', 'ยาก', 'จวบกับ', 'ครั้งนี้', 'ดังกับ', 'ดั่งเคย', 'อันที่จริง', 'ยอมรับ', 'เช่นที่ว่า', 'บัดดล', 'ภายใต้', 'เช่นดังก่อน', 'เช่นดังว่า', 'ก่อนหน้านี้', 'ขึ้น', 'เฉพาะ', 'ปฏิบัติ', 'สูง', 'วัน', 'เธอ', 'นํา', 'บน', 'ทั้งมวล', 'ช่วงท้าย', 'ตามที่', 'มั้ยเนี่ย', 'ขณะที่', 'นั่นเป็น', 'ทั้งนั้นเพราะ', 'ทํา', 'ครัน', 'ถูกต้อง', 'รวมกัน', 'กลุ่มก้อน', 'ด้วย', 'ดั่งกับว่า', 'ช้า', 'เฉยๆ', 'ตรง', 'นั้น', 'ผล', 'ตลอดทั้ง', 'เมื่อไร', 'เท่าไหร่', 'พอๆ', 'ตลอดทั่ว', 'แห่งนั้น', 'ก็จะ', 'ได้', 'จน', 'นัก', 'แบบ', 'แรก', 'คราไหน', 'ผ่านๆ', 'จำเป็น', 'กลับ', 'อย่างดี', 'พวกเธอ', 'ประการ', 'เล่าว่า', 'อย่างไรก็', 'มั้ยล่ะ', 'กว้าง', 'กว้างขวาง', 'ถึงจะ', 'ครั้งคราว', 'จวบ', 'ยก', 'ที่ใด', 'ด้วยเหมือนกัน', 'โตๆ', 'ในเมื่อ', 'ทั้งคน', 'อันเนื่องมาจาก', 'จับ', 'นำพา', 'ค่อยไปทาง', 'นอกเหนือ', 'พวกมัน', 'ผิด', 'เช่นดังที่', 'หากแม้', 'เขา', 'รวมๆ', 'นอกจาก', 'แม้กระทั่ง', 'ใคร', 'ยังคง', 'หรือยัง', 'พร้อมด้วย', 'ทีเดียว', 'นู้น', 'ซะจนกระทั่ง', 'อยาก', 'แท้', 'เหล่านี้', 'นาย', 'ทีใด', 'เสียยิ่ง', 'ไม่ค่อยเป็น', 'สู่', 'ตลอดปี', 'เช่นนี้', 'คราว', 'ใคร่', 'กล่าว', 'ต่างก็', 'ฯลฯ', 'เป็นแต่', 'เคยๆ', 'ที่นี้', 'ส่วนใหญ่', 'แท้จริง', 'ร่วมมือ', 'ถือ', 'ทุกแห่ง', 'เป็นอาทิ', 'แต่', 'ข้างล่าง', 'ก็แค่']\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(pythainlp.corpus.common.thai_stopwords())\n",
    "print(stopwords)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copied from thai2transformers (https://github.com/vistec-AI/thai2transformers/blob/master/thai2transformers/preprocess.py)\n",
    "\"\"\"\n",
    "from typing import Collection, Callable\n",
    "import re\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "_TK_UNK, _TK_REP, _TK_WREP, _TK_URL, _TK_END = \"<unk> <rep> <wrep> <url> </s>\".split()\n",
    "\n",
    "SPACE_SPECIAL_TOKEN = \"<_>\"\n",
    "\n",
    "def rm_brackets(text: str) -> str:\n",
    "    \"\"\"\n",
    "        Remove all empty brackets and artifacts within brackets from `text`.\n",
    "        :param str text: text to remove useless brackets\n",
    "        :return: text where all useless brackets are removed\n",
    "        :rtype: str\n",
    "        :Example:\n",
    "            >>> rm_brackets(\"hey() whats[;] up{*&} man(hey)\")\n",
    "            hey whats up man(hey)\n",
    "    \"\"\"\n",
    "    # remove empty brackets\n",
    "    new_line = re.sub(r\"\\(\\)\", \"\", text)\n",
    "    new_line = re.sub(r\"\\{\\}\", \"\", new_line)\n",
    "    new_line = re.sub(r\"\\[\\]\", \"\", new_line)\n",
    "    # brakets with only punctuations\n",
    "    new_line = re.sub(r\"\\([^a-zA-Z0-9ก-๙]+\\)\", \"\", new_line)\n",
    "    new_line = re.sub(r\"\\{[^a-zA-Z0-9ก-๙]+\\}\", \"\", new_line)\n",
    "    new_line = re.sub(r\"\\[[^a-zA-Z0-9ก-๙]+\\]\", \"\", new_line)\n",
    "    # artifiacts after (\n",
    "    new_line = re.sub(r\"(?<=\\()[^a-zA-Z0-9ก-๙]+(?=[a-zA-Z0-9ก-๙])\", \"\", new_line)\n",
    "    new_line = re.sub(r\"(?<=\\{)[^a-zA-Z0-9ก-๙]+(?=[a-zA-Z0-9ก-๙])\", \"\", new_line)\n",
    "    new_line = re.sub(r\"(?<=\\[)[^a-zA-Z0-9ก-๙]+(?=[a-zA-Z0-9ก-๙])\", \"\", new_line)\n",
    "    # artifacts before )\n",
    "    new_line = re.sub(r\"(?<=[a-zA-Z0-9ก-๙])[^a-zA-Z0-9ก-๙]+(?=\\))\", \"\", new_line)\n",
    "    new_line = re.sub(r\"(?<=[a-zA-Z0-9ก-๙])[^a-zA-Z0-9ก-๙]+(?=\\})\", \"\", new_line)\n",
    "    new_line = re.sub(r\"(?<=[a-zA-Z0-9ก-๙])[^a-zA-Z0-9ก-๙]+(?=\\])\", \"\", new_line)\n",
    "    return new_line\n",
    "\n",
    "def replace_newlines(text: str) -> str:\n",
    "    \"\"\"\n",
    "        Replace newlines in `text` with spaces.\n",
    "        :param str text: text to replace all newlines with spaces\n",
    "        :return: text where all newlines are replaced with spaces\n",
    "        :rtype: str\n",
    "        :Example:\n",
    "            >>> rm_useless_spaces(\"hey whats\\n\\nup\")\n",
    "            hey whats  up\n",
    "    \"\"\"\n",
    "\n",
    "    return re.sub(r\"[\\n]\", \" \", text.strip())\n",
    "\n",
    "def rm_useless_spaces(text: str) -> str:\n",
    "    \"\"\"\n",
    "        Remove multiple spaces in `text`. (code from `fastai`)\n",
    "        :param str text: text to replace useless spaces\n",
    "        :return: text where all spaces are reduced to one\n",
    "        :rtype: str\n",
    "        :Example:\n",
    "            >>> rm_useless_spaces(\"oh         no\")\n",
    "            oh no\n",
    "    \"\"\"\n",
    "    return re.sub(\" {2,}\", \" \", text)\n",
    "\n",
    "def replace_spaces(text: str, space_token: str = SPACE_SPECIAL_TOKEN) -> str:\n",
    "    \"\"\"\n",
    "        Replace spaces with _\n",
    "        :param str text: text to replace spaces\n",
    "        :return: text where all spaces replaced with _\n",
    "        :rtype: str\n",
    "        :Example:\n",
    "            >>> replace_spaces(\"oh no\")\n",
    "            oh_no\n",
    "    \"\"\"\n",
    "    return re.sub(\" \", space_token, text)\n",
    "\n",
    "def replace_rep_after(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace repetitions at the character level in `text`\n",
    "    :param str text: input text to replace character repetition\n",
    "    :return: text with repetitive tokens removed.\n",
    "    :rtype: str\n",
    "    :Example:\n",
    "        >>> text = \"กาาาาาาา\"\n",
    "        >>> replace_rep_after(text)\n",
    "        'กา'\n",
    "    \"\"\"\n",
    "\n",
    "    def _replace_rep(m):\n",
    "        c, cc = m.groups()\n",
    "        return f\"{c}\"\n",
    "\n",
    "    re_rep = re.compile(r\"(\\S)(\\1{3,})\")\n",
    "    return re_rep.sub(_replace_rep, text)\n",
    "\n",
    "def replace_wrep_post(toks: Collection[str]) -> Collection[str]:\n",
    "    \"\"\"\n",
    "    Replace reptitive words post tokenization;\n",
    "    fastai `replace_wrep` does not work well with Thai.\n",
    "    :param Collection[str] toks: list of tokens\n",
    "    :return: list of tokens where repetitive words are removed.\n",
    "    :rtype: Collection[str]\n",
    "    :Example:\n",
    "        >>> toks = [\"กา\", \"น้ำ\", \"น้ำ\", \"น้ำ\", \"น้ำ\"]\n",
    "        >>> replace_wrep_post(toks)\n",
    "        ['กา', 'น้ำ']\n",
    "    \"\"\"\n",
    "    previous_word = None\n",
    "    rep_count = 0\n",
    "    res = []\n",
    "    for current_word in toks + [_TK_END]:\n",
    "        if current_word == previous_word:\n",
    "            rep_count += 1\n",
    "        elif (current_word != previous_word) & (rep_count > 0):\n",
    "            res += [previous_word]\n",
    "            rep_count = 0\n",
    "        else:\n",
    "            res.append(previous_word)\n",
    "        previous_word = current_word\n",
    "    return res[1:]\n",
    "\n",
    "def remove_space(toks: Collection[str]) -> Collection[str]:\n",
    "    \"\"\"\n",
    "    Do not include space for bag-of-word models.\n",
    "    :param Collection[str] toks: list of tokens\n",
    "    :return: Collection of tokens where space tokens (\" \") are filtered out\n",
    "    :rtype: Collection[str]\n",
    "    :Example:\n",
    "        >>> toks = ['ฉัน','เดิน',' ','กลับ','บ้าน']\n",
    "        >>> remove_space(toks)\n",
    "        ['ฉัน','เดิน','กลับ','บ้าน']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for t in toks:\n",
    "        t = t.strip()\n",
    "        if t:\n",
    "            res.append(t)\n",
    "    return res\n",
    "\n",
    "# combine them together\n",
    "def process_transformers(\n",
    "    text: str,\n",
    "    pre_rules: Collection[Callable] = [\n",
    "        rm_brackets,\n",
    "        replace_newlines,\n",
    "        rm_useless_spaces,\n",
    "        replace_spaces,\n",
    "        replace_rep_after,\n",
    "    ],\n",
    "    tok_func: Callable = word_tokenize,\n",
    "    post_rules: Collection[Callable] = [replace_wrep_post],\n",
    ") -> str:\n",
    "    text = text.lower()\n",
    "    for rule in pre_rules:\n",
    "        text = rule(text)\n",
    "    toks = tok_func(text)\n",
    "    for rule in post_rules:\n",
    "        toks = rule(toks)\n",
    "    return \"\".join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.894914Z",
     "iopub.status.busy": "2025-03-03T05:54:47.894667Z",
     "iopub.status.idle": "2025-03-03T05:54:47.902272Z",
     "shell.execute_reply": "2025-03-03T05:54:47.901337Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.894895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.apply(remove_stopwords) # remove unimportant words\n",
    "    text = text.str.replace(r'\\b\\d+\\.\\s*', '', regex=True) # remove index numbers\n",
    "    text = text.str.replace(r'[^\\w\\s\\u0E01-\\u0E5B/]', ' ', regex=True) \n",
    "    text = text.apply(process_transformers) # remove brackets, newlines, spaces, repetitions\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.904023Z",
     "iopub.status.busy": "2025-03-03T05:54:47.903708Z",
     "iopub.status.idle": "2025-03-03T05:54:47.919414Z",
     "shell.execute_reply": "2025-03-03T05:54:47.918503Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.904003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ทดสอบการลบตัวเลข (50/50)!?@# ออกจากข้อความ\n",
      "ทดสอบการลบตัวเลข<_>50/50<_>ออกจากข้อความ\n"
     ]
    }
   ],
   "source": [
    "test = \"1. ทดสอบการลบตัวเลข (50/50)!?@# ออกจากข้อความ\"\n",
    "print(test)\n",
    "print(clean_text(pd.Series([test]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:47.920553Z",
     "iopub.status.busy": "2025-03-03T05:54:47.920270Z",
     "iopub.status.idle": "2025-03-03T05:54:48.066832Z",
     "shell.execute_reply": "2025-03-03T05:54:48.066120Z",
     "shell.execute_reply.started": "2025-03-03T05:54:47.920527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['answer'] = clean_text(df_train['answer'])\n",
    "df_test['answer'] = clean_text(df_test['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:48.067893Z",
     "iopub.status.busy": "2025-03-03T05:54:48.067605Z",
     "iopub.status.idle": "2025-03-03T05:54:48.077130Z",
     "shell.execute_reply": "2025-03-03T05:54:48.076209Z",
     "shell.execute_reply.started": "2025-03-03T05:54:48.067865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train_dq = df_train.drop(columns=['question'])\n",
    "df_train_dq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:48.078513Z",
     "iopub.status.busy": "2025-03-03T05:54:48.078163Z",
     "iopub.status.idle": "2025-03-03T05:54:48.096428Z",
     "shell.execute_reply": "2025-03-03T05:54:48.095544Z",
     "shell.execute_reply.started": "2025-03-03T05:54:48.078479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_q1 = df_train_dq[df_train_dq['set'] == \"Q1\"]\n",
    "df_q2 = df_train_dq[df_train_dq['set'] == \"Q2\"]\n",
    "df_q3 = df_train_dq[df_train_dq['set'] == \"Q3\"]\n",
    "df_q4 = df_train_dq[df_train_dq['set'] == \"Q4\"]\n",
    "\n",
    "display(df_q1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:54:48.097504Z",
     "iopub.status.busy": "2025-03-03T05:54:48.097249Z",
     "iopub.status.idle": "2025-03-03T05:55:08.323949Z",
     "shell.execute_reply": "2025-03-03T05:55:08.323273Z",
     "shell.execute_reply.started": "2025-03-03T05:54:48.097480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, ClassLabel\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:08.325235Z",
     "iopub.status.busy": "2025-03-03T05:55:08.324713Z",
     "iopub.status.idle": "2025-03-03T05:55:10.945046Z",
     "shell.execute_reply": "2025-03-03T05:55:10.944301Z",
     "shell.execute_reply.started": "2025-03-03T05:55:08.325213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:10.946124Z",
     "iopub.status.busy": "2025-03-03T05:55:10.945832Z",
     "iopub.status.idle": "2025-03-03T05:55:11.124518Z",
     "shell.execute_reply": "2025-03-03T05:55:11.123625Z",
     "shell.execute_reply.started": "2025-03-03T05:55:10.946091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# get 90 percentle of the length of the tokenized text\n",
    "X = df_train[\"answer\"].tolist()\n",
    "lengths = [len(test_tokenizer.tokenize(text)) for text in X]\n",
    "max_len = int(np.percentile(lengths, 95))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:11.125694Z",
     "iopub.status.busy": "2025-03-03T05:55:11.125402Z",
     "iopub.status.idle": "2025-03-03T05:55:11.129171Z",
     "shell.execute_reply": "2025-03-03T05:55:11.128343Z",
     "shell.execute_reply.started": "2025-03-03T05:55:11.125671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:11.130445Z",
     "iopub.status.busy": "2025-03-03T05:55:11.130099Z",
     "iopub.status.idle": "2025-03-03T05:55:18.375404Z",
     "shell.execute_reply": "2025-03-03T05:55:18.374520Z",
     "shell.execute_reply.started": "2025-03-03T05:55:11.130402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Load PhayaThaiBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "                MODEL_NAME,\n",
    "                revision='main',\n",
    "                max_length=MAX_LENGTH,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "#create model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    revision='main',\n",
    "    num_labels=12,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:18.376650Z",
     "iopub.status.busy": "2025-03-03T05:55:18.376341Z",
     "iopub.status.idle": "2025-03-03T05:55:18.380562Z",
     "shell.execute_reply": "2025-03-03T05:55:18.379903Z",
     "shell.execute_reply.started": "2025-03-03T05:55:18.376618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a function to compute MSE\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions[0] if isinstance(predictions, tuple) else predictions\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    return {\"mse\": mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:18.381625Z",
     "iopub.status.busy": "2025-03-03T05:55:18.381349Z",
     "iopub.status.idle": "2025-03-03T05:55:18.392720Z",
     "shell.execute_reply": "2025-03-03T05:55:18.391993Z",
     "shell.execute_reply.started": "2025-03-03T05:55:18.381603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Add this before/after running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:55:18.393950Z",
     "iopub.status.busy": "2025-03-03T05:55:18.393649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for q in df_train[\"set\"].unique():\n",
    "    print(f\"Training model for {q}...\")\n",
    "\n",
    "    # Filter data for the current question\n",
    "    df_q = df_train[df_train[\"set\"] == q]\n",
    "\n",
    "    # Prepare features and labels\n",
    "    X = df_q[\"answer\"].tolist()\n",
    "    y = df_q[\"score\"].tolist()\n",
    "    bin_edges = [0, 1.5, 3.5, 5]\n",
    "    bin_labels = [0, 1, 2,]\n",
    "    df_q[\"score_bin\"] = pd.cut(df_q[\"score\"], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "    \n",
    "    # Tokenize input text\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    # Convert data to Hugging Face Dataset format\n",
    "    dataset = Dataset.from_dict({\"text\": X, \"label\": y, \"score_bin\" : df_q['score_bin'].tolist()})\n",
    "    dataset = dataset.cast_column(\"score_bin\", ClassLabel(num_classes=5))\n",
    "    dataset = dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "    # Split into train and validation sets\n",
    "\n",
    "    train_test = dataset.train_test_split(test_size=0.2, seed=RANDOM_STATE, stratify_by_column=\"score_bin\")\n",
    "    train_test[\"train\"] = train_test[\"train\"].remove_columns([\"score_bin\"])\n",
    "    train_test[\"test\"] = train_test[\"test\"].remove_columns([\"score_bin\"])\n",
    "    train_dataset = train_test[\"train\"]\n",
    "    val_dataset = train_test[\"test\"]\n",
    "    \n",
    "\n",
    "    # Load PhayaThaiBERT model for regression (single output neuron)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"weights/model_{q}\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=None,\n",
    "        report_to=\"wandb\", \n",
    "        logging_steps=record_train // (BATCH_SIZE * 10),  \n",
    "    )\n",
    "\n",
    "\n",
    "    # Define Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    wandb.init(project=\"NLP-midterm-2025\", name=f\"V0-{q}-b{BATCH_SIZE}-{NUM_EPOCHS}e\")\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(f\"weights/model_{q}\")\n",
    "    tokenizer.save_pretrained(f\"weights/model_{q}\")\n",
    "    print(f\"Model for {q} saved successfully!\\n\")\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_answer(model_path, text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs).logits.item()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_record = df_train.sample(5)[0]\n",
    "q = sample_record['set']\n",
    "answer = sample_record['answer']\n",
    "score = sample_record['score']\n",
    "\n",
    "model_path = f\"weights/model_{q}\"\n",
    "\n",
    "predicted_score = predict_answer(model_path, answer)\n",
    "print(f\"Predicted Score: {predicted_score}\")\n",
    "print(f\"Expected Score :{score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare output list\n",
    "predictions = []\n",
    "\n",
    "# Device configuration (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    question = row[\"set\"]\n",
    "    answer = row[\"answer\"]\n",
    "\n",
    "    # Load the correct model for the question\n",
    "    model_path = f\"weights/model_{question}\"  # Use best/final model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Tokenize the answer\n",
    "    inputs = tokenizer(answer, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Predict score\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs).logits\n",
    "        predicted_score = output.item()  # Convert tensor to scalar\n",
    "\n",
    "    # Round and clip the score (to match 0-5 scale with 0.25 increments)\n",
    "    rounded_score = torch.clamp(torch.round(torch.tensor(predicted_score) * 4) / 4, 0, 5).item()\n",
    "\n",
    "    # Store result\n",
    "    predictions.append({\"ID\": row[\"ID\"], \"score\": rounded_score})\n",
    "\n",
    "# Convert to DataFrame and save predictions\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv(f\"predictions-BERT.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv(f\"predictions-BERT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(f\"predictions-BERT.csv\")\n",
    "\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df_train.sample(20)\n",
    "\n",
    "predict_answers = []\n",
    "ground_truths = []\n",
    "\n",
    "for _, row in sample_df.iterrows():\n",
    "    question = row[\"set\"]\n",
    "    answer = row[\"answer\"]\n",
    "\n",
    "    # Load the correct model for the question\n",
    "    model_path = f\"weights/model_{question}\"  # Use best/final model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Tokenize the answer\n",
    "    inputs = tokenizer(answer, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Predict score\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs).logits\n",
    "        predicted_score = output.item()  # Convert tensor to scalar\n",
    "\n",
    "    # Round and clip the score (to match 0-5 scale with 0.25 increments)\n",
    "    rounded_score = torch.clamp(torch.round(torch.tensor(predicted_score) * 4) / 4, 0, 5).item()\n",
    "\n",
    "    # Store result\n",
    "    predict_answers.append({\"score\": rounded_score})\n",
    "    ground_truths.append(row[\"score\"])\n",
    "    \n",
    "\n",
    "print(\"MSE for sample data:\", mean_squared_error(ground_truths, predict_answers))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11180927,
     "sourceId": 93859,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dsde-cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
